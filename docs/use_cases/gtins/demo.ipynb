{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Asin</th>\n",
       "      <th>Category</th>\n",
       "      <th>Upc Ean Code</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Url</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Color</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Direction To Use</th>\n",
       "      <th>Is Amazon Seller</th>\n",
       "      <th>Size Quantity Variant</th>\n",
       "      <th>Product Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c69b61db1fc16e7013b43fc926e502d</td>\n",
       "      <td>DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports &amp; Outdoors | Outdoor Recreation | Skate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$237.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/DB-Longboards-CoreFlex-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66d49bbed043f5be260fa9f7fbff5957</td>\n",
       "      <td>Electronic Snap Circuits Mini Kits Classpack, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Learning &amp; Education | Science ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$99.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55324</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Electronic-Circuits-Cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2c55cae269aebf53838484b0d7dd931a</td>\n",
       "      <td>3Doodler Create Flexy 3D Printing Filament Ref...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Arts &amp; Crafts | Craft Kits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$34.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/3Doodler-Plastic-Innova...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18018b6bc416dab347b1b7db79994afa</td>\n",
       "      <td>Guillow Airplane Design Studio with Travel Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Hobbies | Models &amp; Model Kits |...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$28.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Guillow-Airplane-Design...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e04b990e95bf73bbe6a3fa09785d7cd0</td>\n",
       "      <td>Woodstock- Collage 500 pc Puzzle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toys &amp; Games | Puzzles | Jigsaw Puzzles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$17.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62151</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.amazon.com/Woodstock-Collage-500-p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq Id  \\\n",
       "0  4c69b61db1fc16e7013b43fc926e502d   \n",
       "1  66d49bbed043f5be260fa9f7fbff5957   \n",
       "2  2c55cae269aebf53838484b0d7dd931a   \n",
       "3  18018b6bc416dab347b1b7db79994afa   \n",
       "4  e04b990e95bf73bbe6a3fa09785d7cd0   \n",
       "\n",
       "                                        Product Name  Brand Name  Asin  \\\n",
       "0  DB Longboards CoreFlex Crossbow 41\" Bamboo Fib...         NaN   NaN   \n",
       "1  Electronic Snap Circuits Mini Kits Classpack, ...         NaN   NaN   \n",
       "2  3Doodler Create Flexy 3D Printing Filament Ref...         NaN   NaN   \n",
       "3  Guillow Airplane Design Studio with Travel Cas...         NaN   NaN   \n",
       "4                   Woodstock- Collage 500 pc Puzzle         NaN   NaN   \n",
       "\n",
       "                                            Category Upc Ean Code  List Price  \\\n",
       "0  Sports & Outdoors | Outdoor Recreation | Skate...          NaN         NaN   \n",
       "1  Toys & Games | Learning & Education | Science ...          NaN         NaN   \n",
       "2          Toys & Games | Arts & Crafts | Craft Kits          NaN         NaN   \n",
       "3  Toys & Games | Hobbies | Models & Model Kits |...          NaN         NaN   \n",
       "4            Toys & Games | Puzzles | Jigsaw Puzzles          NaN         NaN   \n",
       "\n",
       "  Selling Price  Quantity Model Number  ...  \\\n",
       "0       $237.68       NaN          NaN  ...   \n",
       "1        $99.95       NaN        55324  ...   \n",
       "2        $34.99       NaN          NaN  ...   \n",
       "3        $28.91       NaN          142  ...   \n",
       "4        $17.49       NaN        62151  ...   \n",
       "\n",
       "                                         Product Url Stock Product Details  \\\n",
       "0  https://www.amazon.com/DB-Longboards-CoreFlex-...   NaN             NaN   \n",
       "1  https://www.amazon.com/Electronic-Circuits-Cla...   NaN             NaN   \n",
       "2  https://www.amazon.com/3Doodler-Plastic-Innova...   NaN             NaN   \n",
       "3  https://www.amazon.com/Guillow-Airplane-Design...   NaN             NaN   \n",
       "4  https://www.amazon.com/Woodstock-Collage-500-p...   NaN             NaN   \n",
       "\n",
       "  Dimensions Color Ingredients Direction To Use  Is Amazon Seller  \\\n",
       "0        NaN   NaN         NaN              NaN                 Y   \n",
       "1        NaN   NaN         NaN              NaN                 Y   \n",
       "2        NaN   NaN         NaN              NaN                 Y   \n",
       "3        NaN   NaN         NaN              NaN                 Y   \n",
       "4        NaN   NaN         NaN              NaN                 Y   \n",
       "\n",
       "  Size Quantity Variant  Product Description  \n",
       "0                   NaN                  NaN  \n",
       "1                   NaN                  NaN  \n",
       "2                   NaN                  NaN  \n",
       "3                   NaN                  NaN  \n",
       "4                   NaN                  NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020/data\n",
    "dataset = pd.read_csv(r\"marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create, Save, and Load Priority Products to Collect GTINs For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARTSCAPE</td>\n",
       "      <td>01-0121</td>\n",
       "      <td>ARTSCAPE Etched Glass 24\" x 36\" Window Film, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DC</td>\n",
       "      <td>JAN190710</td>\n",
       "      <td>DC Cover Girls: Black Canary by Joëlle Jones S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LEGO</td>\n",
       "      <td>6288704</td>\n",
       "      <td>LEGO Minecraft Creeper BigFig and Ocelot Chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PLUS</td>\n",
       "      <td>03373</td>\n",
       "      <td>PLUS PLUS - Construction Building Toy, Open Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NKOK</td>\n",
       "      <td>RC-611</td>\n",
       "      <td>NKOK Sonic and Sega All Stars Racing Remote Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand        mpn                                              title\n",
       "8   ARTSCAPE    01-0121  ARTSCAPE Etched Glass 24\" x 36\" Window Film, 2...\n",
       "11        DC  JAN190710  DC Cover Girls: Black Canary by Joëlle Jones S...\n",
       "13      LEGO    6288704  LEGO Minecraft Creeper BigFig and Ocelot Chara...\n",
       "22      PLUS      03373  PLUS PLUS - Construction Building Toy, Open Pl...\n",
       "26      NKOK     RC-611  NKOK Sonic and Sega All Stars Racing Remote Co..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract brand from URL\n",
    "def extract_brand(url):\n",
    "    match = re.search(r'amazon\\.com/([A-Z]+)(?![a-z])', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Apply function to create new column\n",
    "dataset['Brand'] = dataset['Product Url'].apply(extract_brand)\n",
    "dataset[['Product Url','Brand']]\n",
    "\n",
    "priority = dataset[\n",
    "    (dataset['Brand'].isna()==False)&\n",
    "    (dataset['Model Number'].isna()==False)&\n",
    "    (dataset['Upc Ean Code'].isna()==True)\n",
    "    ][['Brand','Model Number','Product Name']]\n",
    "\n",
    "priority.columns = [[\"brand\",\"mpn\",\"title\"]]\n",
    "priority.to_csv('priority.csv')\n",
    "priority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Logs Already Requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>title</th>\n",
       "      <th>api_response</th>\n",
       "      <th>gtin</th>\n",
       "      <th>gtin_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  mpn  title  api_response  gtin  gtin_exists\n",
       "0    NaN  NaN    NaN           NaN   NaN          NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(\"logs.csv\", index_col=False)\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create List of Products not yet run through Produkter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'mpn' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16380\\1375419449.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpriority\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mpn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mpn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_priority'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# # Filter rows that exist in the first dataframe but not in the second\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# result_df = merged_df[merged_df['_merge'] == 'left_only']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vanal\\Desktop\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m ) -> DataFrame:\n\u001b[1;32m--> 148\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vanal\\Desktop\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    733\u001b[0m         (\n\u001b[0;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;31m# to avoid incompatible dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vanal\\Desktop\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1217\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vanal\\Desktop\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1788\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m                 \u001b[0mmulti_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m             \u001b[0mlabel_axis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"column\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 \u001b[1;34mf\"The {label_axis_name} label '{key}' is not unique.{multi_message}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m             )\n\u001b[0;32m   1795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The column label 'mpn' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level."
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(priority, log, left_on='mpn', right_on='mpn', how='left', indicator=True, suffixes=('_priority', '_log'))\n",
    "merged_df\n",
    "# # Filter rows that exist in the first dataframe but not in the second\n",
    "# result_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# # Drop the '_merge' column as it's no longer needed\n",
    "# result_df = result_df.drop(columns=['_merge'])\n",
    "\n",
    "# # Drop duplicate '_y' columns\n",
    "# result_df = result_df.loc[:, ~result_df.columns.str.endswith('_y')]\n",
    "\n",
    "# # Rename remaining columns to remove '_x' suffixes\n",
    "# todo = result_df.rename(columns=lambda x: x[:-2] if x.endswith('_x') else x)\n",
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gtin_values(response_json, q, gtin_key='gtin'):\n",
    "    try:\n",
    "        gtin_values = response_json.get(q, {}).get(gtin_key, [])\n",
    "        \n",
    "        # Filter out None values and strings with length < 5 characters\n",
    "        filtered_values = [value for value in gtin_values if value is not None and (not isinstance(value, str) or len(value) > 5)]\n",
    "    \n",
    "    except: # no response_json\n",
    "        filtered_values = []    \n",
    "\n",
    "    return filtered_values\n",
    "# get_gtin_values(data, q, gtin_key='gtin12')\n",
    "\n",
    "\n",
    "def filter_strings(*lists):\n",
    "    result = []\n",
    "    for lst in lists:\n",
    "        for item in lst:\n",
    "            if isinstance(item, str) and len(item) > 5:\n",
    "                result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def any_list_non_empty(*lists):\n",
    "    for l in lists:\n",
    "        if l:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect GTINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://produkter.p.rapidapi.com/schemas\"\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"XXXXXXXXXXXXX\",\n",
    "\t\"X-RapidAPI-Host\": \"produkter.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "for i, row in df.iloc[:10,:].iterrows():\n",
    "\tquerystring = {\"q\":f\"{row['Brand']} {row['Model Number']}\"}\t\t\n",
    "\tresponse = requests.get(url, headers=headers, params=querystring)\n",
    "\tprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize `log` column variables for each `todo` row\n",
    "i_brand = None\n",
    "i_mpn = None\n",
    "i_title = None\n",
    "i_api_response = None\n",
    "i_gtin = None\n",
    "i_gtin8 = None\n",
    "i_gtin12 = None\n",
    "i_gtin13 = None\n",
    "i_gtin_exists = None\n",
    "\n",
    "# Initialize a list to store rows\n",
    "output_rows = []\n",
    "\n",
    "for i, row in todo.iloc[:50, :].iterrows():\n",
    "    \n",
    "    i_brand = row['brand']\n",
    "    i_mpn = row['mpn']\n",
    "    i_title = row['title']\n",
    "    print(i_brand,i_mpn)\n",
    "\n",
    "    querystring = {\"q\": f\"{i_brand} {i_mpn}\"}\n",
    "\n",
    "    # try requests + store i_api_response\n",
    "    try:\n",
    "        # Set a timeout of 25 seconds for the request\n",
    "        response = requests.get(url, headers=headers, params=querystring, timeout=35)\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            # Check response status code\n",
    "            if response.status_code == 200:\n",
    "                i_api_response = \"200\"\n",
    "            else:\n",
    "                i_api_response = \"not 200\"\n",
    "        except Exception as e:\n",
    "            response_json = None\n",
    "            i_api_response = e\n",
    "            \n",
    "    except requests.Timeout:\n",
    "        # Request timed out\n",
    "        response_json = None\n",
    "        i_api_response = \"timeout\"\n",
    "\n",
    "        \n",
    "\n",
    "    # get gtins\n",
    "    try:\n",
    "        i_gtin = get_gtin_values(response_json, q=f\"{i_brand} {i_mpn}\", gtin_key='gtin')\n",
    "        i_gtin8 = get_gtin_values(response_json, q=f\"{i_brand} {i_mpn}\", gtin_key='gtin8')\n",
    "        i_gtin12 = get_gtin_values(response_json, q=f\"{i_brand} {i_mpn}\", gtin_key='gtin12')\n",
    "        i_gtin13 = get_gtin_values(response_json, q=f\"{i_brand} {i_mpn}\", gtin_key='gtin13')\n",
    "        \n",
    "        filter_strings(i_gtin,i_gtin8,i_gtin12,i_gtin13)\n",
    "\n",
    "        i_gtin_exists = any_list_non_empty(i_gtin,i_gtin8,i_gtin12,i_gtin13)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors here\n",
    "        print(f\"Error processing gtins on row {i} ({i_brand} {i_mpn}): \\n {e}\")\n",
    "        i_gtin = []\n",
    "        i_gtin8 = []\n",
    "        i_gtin12 = []\n",
    "        i_gtin13 = []\n",
    "        \n",
    "        i_gtin_exists = any_list_non_empty(i_gtin,i_gtin8,i_gtin12,i_gtin13)\n",
    "\n",
    "    \n",
    "    # make new rows\n",
    "    new_row = {\n",
    "        'zoroNo':i_zoroNo,\n",
    "        'brand':i_brand,\n",
    "        'mpn':i_mpn,\n",
    "        'title':i_title,\n",
    "        'api_response':i_api_response,\n",
    "        'gtin':i_gtin,\n",
    "        'gtin8':i_gtin8,\n",
    "        'gtin12':i_gtin12,\n",
    "        'gtin13':i_gtin13,\n",
    "        'gtin_exists':i_gtin_exists\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    output_rows.append(new_row)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logs = pd.DataFrame(output_rows)\n",
    "new_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the list of dictionaries\n",
    "new_logs = pd.DataFrame(output_rows)\n",
    "\n",
    "new_logs.to_csv('./requested_logs.csv', index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup duplicates if they exist\n",
    "\n",
    "# Read the updated CSV file into a DataFrame\n",
    "log = pd.read_csv('./requested_logs.csv')\n",
    "\n",
    "# Drop duplicates in the \"zoroNo\" column, keeping the record where \"gtin_exists\" is True if duplicates exist\n",
    "log = log.sort_values('gtin_exists', ascending=False).drop_duplicates(subset='zoroNo')\n",
    "\n",
    "# Write the filtered DataFrame back to the CSV file\n",
    "log.to_csv('./requested_logs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on GTIN Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "log = pd.read_csv(\"logs.csv\", index_col=False)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response = log.groupby(by=\"api_response\")['mpn'].count()\n",
    "api_response = api_response.rename('count').reset_index().rename(columns={'api_response': 'api_response'})\n",
    "\n",
    "print(f\"SKUs Requested: {sum(api_response['count'])}\")\n",
    "display(api_response)\n",
    "\n",
    "fig = px.bar(api_response, x=\"api_response\", y='count',title=\"GTIN Collection Logs | API Responses\")\n",
    "\n",
    "# Annotate each bar with the percentage\n",
    "for i in range(len(api_response)):\n",
    "    total_count = api_response['count'].sum()\n",
    "    percentage = (api_response.iloc[i]['count'] / total_count) * 100\n",
    "    fig.add_annotation(x=api_response.index[i], y=api_response.iloc[i]['count'] + 10, \n",
    "                       text=f\"{percentage:.2f}%\", showarrow=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtin_exists = log.groupby(by=\"gtin_exists\")['mpn'].count()\n",
    "gtin_exists = gtin_exists.rename('count').reset_index().rename(columns={'gtin_exists': 'gtin_exists'})\n",
    "\n",
    "print(f\"SKUs Requested: {sum(gtin_exists['count'])}\")\n",
    "display(gtin_exists)\n",
    "\n",
    "fig = px.bar(gtin_exists, x=\"gtin_exists\", y='count',title=\"GTIN Collection Logs | GTINs Found\")\n",
    "\n",
    "# Annotate each bar with the percentage\n",
    "for i in range(len(gtin_exists)):\n",
    "    total_count = gtin_exists['count'].sum()\n",
    "    percentage = (gtin_exists.iloc[i]['count'] / total_count) * 100\n",
    "    fig.add_annotation(x=gtin_exists.index[i], y=gtin_exists.iloc[i]['count'] + 10, \n",
    "                       text=f\"{percentage:.2f}%\", showarrow=False)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
